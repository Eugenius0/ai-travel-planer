{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# üöÄ AI Travel Planner - LLM Inference Notebook\n","\n","This notebook demonstrates how to load our fine-tuned Llama-based LLM from HuggingFace and use it to generate interactive responses for travel-related queries. We use Gradio as UI component so that the model's capabilities can be experienced through a user-friendly interface and we use Gradio deploy to create a public URL.\n","\n","**Note**: This approach is implemented as a workaround based on the TA's suggestion to address the issue of `AssertionError: Torch not compiled with CUDA enabled` encountered in HuggingFace Spaces due to the lack of GPU support. For more details, refer to the [discussion on Canvas](https://canvas.kth.se/courses/50172/discussion_topics/432284)."],"metadata":{"id":"ibrgZ3D8Mu4H"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"IYX3jr6PpUT_","executionInfo":{"status":"ok","timestamp":1733854830644,"user_tz":-60,"elapsed":23792,"user":{"displayName":"Eugenius","userId":"16883495389156489089"}}},"outputs":[],"source":["%%capture\n","!pip install unsloth\n","# Also get the latest nightly Unsloth!\n","# !pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"]},{"cell_type":"code","source":["!pip install -U bitsandbytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydSU4z8CpveT","executionInfo":{"status":"ok","timestamp":1733854835726,"user_tz":-60,"elapsed":5086,"user":{"displayName":"Eugenius","userId":"16883495389156489089"}},"outputId":"f6b778b9-0b3d-4c50-d27f-df3c9aa4ebee"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"]}]},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjRrln7gN4B9","executionInfo":{"status":"ok","timestamp":1733854927801,"user_tz":-60,"elapsed":6977,"user":{"displayName":"Eugenius","userId":"16883495389156489089"}},"outputId":"09eef569-e0fa-4b25-e479-c50cf0da4e9b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.8.0)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n","Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.1)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.0)\n","Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.3)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.19)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n","Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.2)\n","Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n","Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.9.0)\n","Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (14.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"]}]},{"cell_type":"code","source":["from transformers import AutoModel, AutoTokenizer\n","max_seq_length = 2048\n","dtype = None\n","\n","model_name_or_path = \"Eugenius0/lora_model_tuned\"\n","\n","from unsloth import FastLanguageModel\n","import torch\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = model_name_or_path,\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = True,\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ys3fHzkqmAI","executionInfo":{"status":"ok","timestamp":1733856073699,"user_tz":-60,"elapsed":13512,"user":{"displayName":"Eugenius","userId":"16883495389156489089"}},"outputId":"6b2cb2be-0684-4fa5-dc1d-aef4728d8b94"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}]},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","# model, tokenizer = FastLanguageModel.from_pretrained(\n","#       model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","#       max_seq_length = max_seq_length,\n","#       dtype = dtype,\n","#       load_in_4bit = load_in_4bit,\n","#   )\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": \"In which state is Freiburg im Breisgau and name its most famous sight?.\"},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize = True,\n","    add_generation_prompt = True, # Must add for generation\n","    return_tensors = \"pt\",\n",").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n","_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n","                   use_cache = True, temperature = 1.5, min_p = 0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RvSTNtYhtcwW","executionInfo":{"status":"ok","timestamp":1733855523880,"user_tz":-60,"elapsed":2555,"user":{"displayName":"Eugenius","userId":"16883495389156489089"}},"outputId":"92fdbdda-40d8-4a39-c651-26bba9a50e16"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Freiburg im Breisgau is in Germany, and its most famous sight is the Freiburger M√ºnster, a medieval Gothic-style cathedral with a distinctive south tower.<|eot_id|>\n"]}]},{"cell_type":"code","source":["# Measure Performance based on Human Judgement\n","from unsloth import FastLanguageModel\n","# model, tokenizer = FastLanguageModel.from_pretrained(\n","#       model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","#       max_seq_length = max_seq_length,\n","#       dtype = dtype,\n","#       load_in_4bit = load_in_4bit,\n","#   )\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": \"How high is the Feldberg in the Black Forest?\"},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize = True,\n","    add_generation_prompt = True, # Must add for generation\n","    return_tensors = \"pt\",\n",").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n","_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n","                   use_cache = True, temperature = 1.5, min_p = 0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zi6aKoUWIttQ","executionInfo":{"status":"ok","timestamp":1733849906104,"user_tz":-60,"elapsed":3319,"user":{"displayName":"Eugenius","userId":"16883495389156489089"}},"outputId":"3af5b913-07e1-4ae5-d556-24c3c3071222"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["The Feldberg, which is a mountain in the Black Forest (Schwarzwald) in Germany, has an elevation of 1,493 meters (4,893 feet).<|eot_id|>\n"]}]},{"cell_type":"code","source":["# Measure Performance\n","import time\n","from transformers import TextIteratorStreamer\n","\n","# Example test queries\n","test_queries = [\n","    {\n","        \"query\": \"In which state is Freiburg im Breisgau and name its most famous sight?\",\n","    },\n","    {\n","        \"query\": \"What are the main attractions in Paris?\",\n","    },\n","]\n","\n","performance_results = []\n","\n","for test in test_queries:\n","    query = test[\"query\"]\n","\n","    messages = [{\"role\": \"user\", \"content\": query}]\n","    inputs = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=True,\n","        add_generation_prompt=True,\n","        return_tensors=\"pt\",\n","    ).to(\"cuda\")\n","\n","    # Measure inference time\n","    start_time = time.time()\n","    streamer = TextIteratorStreamer(\n","        tokenizer, skip_prompt=True, skip_special_tokens=True, timeout=10.0\n","    )\n","\n","    # Start generation in a separate thread\n","    import threading\n","    generation_thread = threading.Thread(\n","        target=model.generate,\n","        kwargs={\n","            \"input_ids\": inputs,\n","            \"streamer\": streamer,\n","            \"max_new_tokens\": 128,\n","            \"use_cache\": True,\n","            \"temperature\": 1.5,\n","            \"min_p\": 0.1,\n","        },\n","    )\n","    generation_thread.start()\n","\n","    # Collect response as it streams\n","    response = \"\"\n","    for token in streamer:\n","        response += token\n","\n","    end_time = time.time()\n","\n","    # Log results\n","    performance_results.append({\n","        \"Query\": query,\n","        \"Generated Output\": response,\n","        \"Inference Time (s)\": round(end_time - start_time, 4),\n","    })\n","\n","# Display results\n","import pandas as pd\n","pd.set_option(\"display.max_colwidth\", None)\n","results_df = pd.DataFrame(performance_results)\n","print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MvczVLtQ973s","executionInfo":{"status":"ok","timestamp":1733850018947,"user_tz":-60,"elapsed":11264,"user":{"displayName":"Eugenius","userId":"16883495389156489089"}},"outputId":"98d44f20-3b3e-49d6-de23-9d9a09a3663b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                                    Query  \\\n","0  In which state is Freiburg im Breisgau and name its most famous sight?   \n","1                                 What are the main attractions in Paris?   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Generated Output  \\\n","0                                                                                                                                                                                                                                                                                                          Freiburg im Breisgau is located in the state of Baden-W√ºrttemberg in Germany. It is famous for its Gothic Cathedral of the Immaculate Conception. This stunning cathedral was completed in 1343 and stands as an exemplary representation of medieval architecture in the Black Forest region.   \n","1  There are many famous landmarks and museums in Paris. Some of the main attractions include:\\n\\n1. The Eiffel Tower - This is one of the most iconic and photographed buildings in the world, standing 1,063 feet high. You can take an elevator or stairs to the top for spectacular views of the city.\\n\\n2. The Louvre - This is the world's largest art museum, housing a collection of more than 550,000 works of art, including the Mona Lisa and the Venus de Milo.\\n\\n3. Notre Dame Cathedral - This beautiful Gothic cathedral was built in the 12th century and is considered one of the most   \n","\n","   Inference Time (s)  \n","0              3.5184  \n","1              7.5187  \n"]}]},{"cell_type":"markdown","source":["## Bleu Scores"],"metadata":{"id":"pyHb5DUR45aG"}},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYbQFjLu42V1","executionInfo":{"status":"ok","timestamp":1733855533850,"user_tz":-60,"elapsed":2841,"user":{"displayName":"Eugenius","userId":"16883495389156489089"}},"outputId":"7ba97632-fceb-4759-afc6-74af637bdbf8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"]}]},{"cell_type":"code","source":["import re\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from transformers import TextIteratorStreamer\n","import pandas as pd\n","import time\n","import threading\n","\n","# Function to normalize text\n","def normalize_text(text):\n","    \"\"\"Lowercase and remove punctuation from a given text.\"\"\"\n","    text = text.lower()  # Convert to lowercase\n","    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n","    return text\n","\n","# Example test queries and references\n","test_queries = [\n","    {\"query\": \"Translate this from English into German: Freiburg is in Baden-W√ºrttemberg and its most famous sight is the Freiburger M√ºnster.\",\n","     \"reference\": \"Freiburg liegt in Baden-W√ºrttemberg und seine ber√ºhmteste Sehensw√ºrdigkeit ist das Freiburger M√ºnster.\"},\n","    {\"query\": \"Translate this from English into French: The main attractions in Paris include the Eiffel Tower, the Louvre, and Notre-Dame Cathedral.\",\n","     \"reference\": \"Les principales attractions de Paris incluent la Tour Eiffel, le Louvre et la Cath√©drale Notre-Dame.\"},\n","]\n","\n","performance_results = []\n","\n","# Smoothing function for BLEU score\n","smoothing_function = SmoothingFunction().method1\n","\n","for test in test_queries:\n","    query = test[\"query\"]\n","    reference = test[\"reference\"]\n","\n","    # Prepare input\n","    messages = [{\"role\": \"user\", \"content\": query}]\n","    inputs = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=True,\n","        add_generation_prompt=True,\n","        return_tensors=\"pt\",\n","    ).to(\"cuda\")\n","\n","    # Generate response\n","    response = \"\"\n","    streamer = TextIteratorStreamer(\n","        tokenizer, skip_prompt=True, skip_special_tokens=True, timeout=10.0\n","    )\n","\n","    generation_thread = threading.Thread(\n","        target=model.generate,\n","        kwargs={\n","            \"input_ids\": inputs,\n","            \"streamer\": streamer,\n","            \"max_new_tokens\": 128,\n","            \"use_cache\": True,\n","            \"temperature\": 1.5,\n","            \"min_p\": 0.1,\n","        },\n","    )\n","    generation_thread.start()\n","\n","    for token in streamer:\n","        response += token\n","\n","    # Normalize the generated output and reference\n","    normalized_response = normalize_text(response)\n","    normalized_reference = normalize_text(reference)\n","\n","    # Compute BLEU score\n","    bleu_score = sentence_bleu([normalized_reference.split()], normalized_response.split(), smoothing_function=smoothing_function)\n","\n","    # Log results\n","    performance_results.append({\n","        \"Query\": query,\n","        \"Generated Output\": response.strip(),\n","        \"BLEU Score\": round(bleu_score, 4),\n","    })\n","\n","# Display results\n","pd.set_option(\"display.max_colwidth\", None)\n","results_df = pd.DataFrame(performance_results)\n","print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cw1NzeZo-KaA","executionInfo":{"status":"ok","timestamp":1733855559784,"user_tz":-60,"elapsed":22373,"user":{"displayName":"Eugenius","userId":"16883495389156489089"}},"outputId":"513070f5-7031-4c4a-eb74-d00b714a42df"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                                                                                                    Query  \\\n","0          Translate this from English into German: Freiburg is in Baden-W√ºrttemberg and its most famous sight is the Freiburger M√ºnster.   \n","1  Translate this from English into French: The main attractions in Paris include the Eiffel Tower, the Louvre, and Notre-Dame Cathedral.   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Generated Output  \\\n","0                                                                                                                                                                                                                                                                                                                                                       The translation of the English text into German is:\\nFreiburg ist in Baden-W√ºrttemberg und die bekannteste Sehensw√ºrdigkeit ist der Freiburger M√ºnster.   \n","1  Translation: \"Les principaux attractions √† Paris incluent la Tour Eiffel, le Louvre, et la Cath√©drale Notre-Dame.\"\\n\\nHere's the translation:\\n- \"The\" is translated as \"les\".\\n- \"main attractions\" is translated as \"principaux attractions\".\\n- \"in\" is translated as \"√†\".\\n- \"Paris\" is left unchanged since it is the proper noun representing a place name.\\n- \"Eiffel Tower\" is translated as \"Tour Eiffel\".\\n- \"the Louvre\" is translated as \"le Louvre\".\\n- \"Notre-Dame Cathedral\" is translated as   \n","\n","   BLEU Score  \n","0      0.0687  \n","1      0.1457  \n"]}]},{"cell_type":"code","source":["import gradio as gr\n","from unsloth import FastLanguageModel\n","from transformers import TextIteratorStreamer\n","import torch\n","import threading\n","\n","# Load the fine-tuned model and tokenizer\n","model_name_or_path = \"Eugenius0/lora_model_tuned\"\n","max_seq_length = 2048\n","dtype = None\n","\n","# Detect and set the appropriate device\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")\n","\n","# Load the model and tokenizer\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=model_name_or_path,\n","    max_seq_length=max_seq_length,\n","    dtype=dtype,\n","    load_in_4bit=True,\n",")\n","FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n","\n","# Define the travel planner response generation logic\n","def generate_travel_plan(city, preferences, nb_days):\n","    try:\n","        prompt = (\n","            f\"Create a travel plan to visit {city} during {nb_days} days, focusing on {preferences}. Include suggested activities, \"\n","            f\"landmarks to visit, and any local tips.\"\n","        )\n","        messages = [{\"role\": \"user\", \"content\": prompt}]\n","        inputs = tokenizer.apply_chat_template(\n","            messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\"\n","        ).to(device)  # Use the detected device\n","\n","        # Generate the response in a single step\n","        outputs = model.generate(\n","            input_ids=inputs,\n","            max_new_tokens=1024,\n","            use_cache=True,\n","            temperature=1.2,\n","            repetition_penalty=1.1,  # Avoid repetitive loops\n","            min_p=0.1,\n","        )\n","        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return response\n","\n","    except Exception as e:\n","        error_message = f\"Error during response generation: {e}\"\n","        print(error_message)\n","        return error_message\n","\n","# Simplified Gradio UI for Travel Planner\n","interface = gr.Interface(\n","    fn=generate_travel_plan,\n","    inputs=[\n","        gr.Textbox(label=\"City\", placeholder=\"Enter the city you want to visit\"),\n","        gr.Textbox(label=\"Preferences\", placeholder=\"E.g., historical sites, food, nightlife\"),\n","        gr.Number(label=\"Trip Duration (Days)\", value=1, interactive=True, minimum=1, maximum=7),\n","    ],\n","    outputs=gr.Textbox(label=\"Generated Travel Plan\"),\n","    title=\"AI Travel Planner\",\n","    description=(\n","        \"Plan your trips with the help of an AI Travel Planner! \"\n","        \"Enter the city you want to visit, your preferences, and the duration of your trip, \"\n","        \"and get a personalized itinerary tailored to your interests.\"\n","    ),\n","    examples=[\n","        [\"Paris\", \"art museums, romantic spots\", 2],\n","        [\"Tokyo\", \"anime culture, food, nightlife\", 1],\n","        [\"New York\", \"Broadway, Central Park, landmarks\", 3],\n","    ],\n",")\n","\n","# Launch Gradio app\n","interface.launch(share=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":708},"id":"itra1sX3PTej","executionInfo":{"status":"ok","timestamp":1733856128409,"user_tz":-60,"elapsed":11882,"user":{"displayName":"Eugenius","userId":"16883495389156489089"}},"outputId":"0b0d97e5-8702-47fe-d747-32887c383256"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://888fbed536d4fc2252.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://888fbed536d4fc2252.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":13}]}]}